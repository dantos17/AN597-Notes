---
title: "Module09 Notes"
author: "Dani Antos"
date: "September 28, 2017"
output: html_document
---

We're talking about statistical inference and hypothesis testing

**critical value** corresponds to the quantile limits of interest; +/- 1-(alpha/2)
```{r}
n <- 1000
mu <- 3.5
sigma <- 4
v <- rnorm(n, mu, sigma)
s <- sample(v, size = 30, replace = FALSE)
s
m <- mean(s)
m
sd <- sd(s)
sd
sem <- sd(s)/sqrt(length(S))
sem
lower <- m- qnorm(1-0.05/2)*sem
upper <- m+ qnorm(1-0.05/2)*sem
ci<- c(lower, upper)
ci
```

**Central Limit Theorem**= distribution of averages and independent & identically distributed (iid) random variables becomes normal as the sample size increases. Allows us to have a good sense of the mean and distribution of average events in a population, and to make inferences about a population based on a sample.

Example- we're taking averages of samples from a non-normal distribution. Using Poisson distribution where lambda=14, so mu and sigma^2 are equal to lambda. Using sample size n=10
```{r}
lambda <- 14
n <- 10
pop_se <- sqrt(lambda/n)
pop_se
x <- NULL
for (i in 1:1000) {
    x[i] <- mean(rpois(n = n, lambda = lambda))
}
hist(x, breaks = seq(from = lambda - 4 * sqrt(lambda)/sqrt(n), to = lambda + 
    4 * sqrt(lambda)/sqrt(n), length.out = 20), probability = TRUE)
sd <- sd(x)
sd
qqnorm(x)
qqline(x)
```

Repeating the example, except n=100, not 10.
```{r}
n <- 100
pop_se <- sqrt(lambda/n)
pop_se
x <- NULL
for (i in 1:1000) {
    x[i] <- mean(rpois(n = n, lambda = lambda))
}
hist(x, breaks = seq(from = lambda - 4 * sqrt(lambda)/sqrt(n), to = lambda + 
    4 * sqrt(lambda)/sqrt(n), length.out = 20), probability = TRUE)
sd <- sd(x)
sd
qqnorm(x)
qqline(x)
curve(dnorm(x, 0, 1), -4, 4, ylim = c(0, 0.8))
z <- (x - lambda)/pop_se
hist(z, breaks = seq(from = -4, to = 4, length.out = 20), probability = TRUE, 
    add = TRUE)
```

CLT example using sum instead of mean
```{r}
n <- 100
x <- NULL
for (i in 1:1000) {
    x[i] <- sum(rpois(n = n, lambda = lambda))
}
hist(x, breaks = seq(min(x), max(x), length.out = 20), probability = TRUE)
```

So basically, a distribution of averages will be approximately normal, will be centered at the population mean, and the sd will be roughly equal to the se of the mean. As sample size increases, the standard error of the mean decreases and the distribution becomes more normal.

We can construct confidence intervals for statistics OTHER THAN the mean
```{r challenge 1}
n <- 1000
x <- 856
phat <- x/n

phat
n * phat
n * (1-phat)
pop_se <- sqrt((phat) * (1 - phat)/n)
pop_se
#setting up 95% CI
curve(dnorm(x, mean = phat, sd = pop_se), phat - 4 * pop_se, phat + 4 * pop_se)
upper <- phat + qnorm(0.975) * pop_se
lower <- phat - qnorm(0.975) * pop_se
ci <- c(lower, upper)
polygon(cbind(c(ci[1], seq(from = ci[1], to = ci[2], length.out = 1000), ci[2]), 
    c(0, dnorm(seq(from = ci[1], to = ci[2], length.out = 1000), mean = phat, 
        sd = pop_se), 0)), border = "black", col = "gray")
abline(v = ci)
abline(h = 0)
```

#Small Sample Confidence Intervals
if n<30, then we use the t distribution. It's similar in shape to the normal distribution: bell shaped, symmetric, and unimodal.
```{r}
mu <- 0
sigma <- 1
curve(dnorm(x, mu, 1), mu - 4 * sigma, mu + 4 * sigma, main = "Normal Curve=red\nStudent's t=blue", 
    xlab = "x", ylab = "f(x)", col = "red", lwd = 3)
for (i in c(1, 2, 3, 4, 5, 10, 20, 100)) {
    curve(dt(x, df = i), mu - 4 * sigma, mu + 4 * sigma, main = "T Curve", xlab = "x", 
        ylab = "f(x)", add = TRUE, col = "blue", lty = 5)
}
n <- 1e+05
mu <- 3.5
sigma <- 4
x <- rnorm(n, mu, sigma)
sample_size <- 30
s <- sample(x, size = sample_size, replace = FALSE)
m <- mean(s)
m
sd <- sd(s)
sd
sem <- sd(s)/sqrt(length(s))
sem
lower <- m - qnorm(1 - 0.05/2) * sem
upper <- m + qnorm(1 - 0.05/2) * sem
ci_norm <- c(lower, upper)
ci_norm
#ci for a t distribution
lower <- m - qt(1 - 0.05/2, df = sample_size - 1) * sem
upper <- m + qt(1 - 0.05/2, df = sample_size - 1) * sem
ci_t <- c(lower, upper)
ci_t
#what if the sample size is much smaller than 30, ie 5?
sample_size <- 5
s <- sample(x, size = sample_size, replace = FALSE)
m <- mean(s)
m
sd <- sd(s)
sd
sem <- sd(s)/sqrt(length(s))
sem
lower <- m - qnorm(1 - 0.05/2) * sem
ci_norm <- c(lower, upper)
ci_norm
lower <- m - qt(1 - 0.05/2, df = sample_size - 1) * sem
upper <- m + qt(1 - 0.05/2, df = sample_size - 1) * sem
ci_t <- c(lower, upper)
ci_t
```

